{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205b0a6c",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction with Interpretable Models\n",
    "\n",
    "This notebook focuses on building baseline machine learning models for customer churn prediction.\n",
    "The emphasis is not only on predictive performance, but also on **interpretability**, which is crucial\n",
    "for understanding customer behavior and supporting business decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38760021",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation\n",
    "\n",
    "We load the dataset and prepare features for modeling. Identifier variables\n",
    "are removed, and categorical variables are encoded using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dba831",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "# Convert TotalCharges to numeric\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# Target variable\n",
    "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5058b",
   "metadata": {},
   "source": [
    "## Feature Selection and Train-Test Split\n",
    "\n",
    "We separate the target variable (`Churn`) from input features and perform a standard train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Churn\", \"customerID\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b585b9a",
   "metadata": {},
   "source": [
    "## Logistic Regression (Interpretable Baseline)\n",
    "\n",
    "Logistic regression serves as a strong and interpretable baseline model for churn prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc57d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"logisticregression\", LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict_proba(X_test)[:, 1]\n",
    "roc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "roc_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb614d9b",
   "metadata": {},
   "source": [
    "## Decision Tree (Non-linear Baseline)\n",
    "\n",
    "A decision tree is trained as a comparison model to capture non-linear patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"decisiontree\", DecisionTreeClassifier(\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_tree = tree.predict_proba(X_test)[:, 1]\n",
    "roc_tree = roc_auc_score(y_test, y_pred_tree)\n",
    "\n",
    "roc_tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a709763",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Logistic regression slightly outperforms the decision tree in terms of ROC-AUC.\n",
    "Given its superior interpretability and competitive performance, logistic regression\n",
    "is selected for deeper analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42438b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = log_reg.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "classifier = list(log_reg.named_steps.values())[-1]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": classifier.coef_[0]\n",
    "}).sort_values(by=\"coefficient\", ascending=False)\n",
    "\n",
    "coef_df.head(10), coef_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify most influential features (by absolute coefficient value)\n",
    "coef_df[\"abs_coefficient\"] = coef_df[\"coefficient\"].abs()\n",
    "\n",
    "coef_df.sort_values(\"abs_coefficient\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353325d1",
   "metadata": {},
   "source": [
    "## Interpretation of Logistic Regression Coefficients\n",
    "\n",
    "- Contract type is the strongest driver of churn, especially month-to-month contracts.\n",
    "- Higher monthly charges are associated with increased churn probability.\n",
    "- Customer tenure strongly reduces churn risk, reflecting accumulated loyalty.\n",
    "- Electronic check payment is correlated with higher churn.\n",
    "- Value-added services such as online security or tech support reduce churn likelihood.\n",
    "\n",
    "These findings align with domain intuition and suggest that the model captures meaningful\n",
    "customer behavior patterns rather than spurious correlations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
